{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:#00A'>O código adiante obtém os arquivos csv, por tipo (rat, rat_evetivo, rat_viatura e rat_produtividade) e os ordena por data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = os.getcwd()\n",
    "# rats_files_names = os.listdir(dir+'/files/RAT')\n",
    "# rat_pattern = re.compile('REDS_RAT_2')\n",
    "# rat_viatura_pattern = re.compile('RAT_VIATURA')\n",
    "# rat_efetivo_pattern = re.compile('RAT_EFETIVO')\n",
    "# rat_produtividade_pattern = re.compile('RAT_Produtividade')\n",
    "\n",
    "# rats_files = list()\n",
    "# rats_viatura_files = list()\n",
    "# rats_efetivo_files = list()\n",
    "# rats_produtividade_files = list()\n",
    "\n",
    "# for file_name in rats_files_names:\n",
    "#     is_rat = rat_pattern.search(file_name) != None\n",
    "#     is_rat_viatura = rat_viatura_pattern.search(file_name) != None\n",
    "#     is_rat_efetivo = rat_efetivo_pattern.search(file_name) != None\n",
    "#     is_rat_produtividade = rat_produtividade_pattern.search(file_name) != None\n",
    "#     if is_rat:\n",
    "#         rats_files.append(file_name)\n",
    "#     elif is_rat_viatura:\n",
    "#         rats_viatura_files.append(file_name)\n",
    "#     elif is_rat_efetivo:\n",
    "#         rats_efetivo_files.append(file_name)\n",
    "#     elif is_rat_produtividade:\n",
    "#         rats_produtividade_files.append(file_name)\n",
    "        \n",
    "# rats_files.sort(key=lambda name: int(name[9:17]))\n",
    "# rats_viatura_files.sort(key=lambda name: int(name[18:26]))\n",
    "# rats_efetivo_files.sort(key=lambda name: int(name[18:26]))\n",
    "# rats_produtividade_files.sort(key=lambda name: int(name[23:31]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#0A0;margin:10px \">Importação, para o Banco de Dados, de todos os arquivos tipo RAT</h2>\n",
    "<h3 style=\"color:#00A; margin:10px\">Importa somente os dados do 23º BPM</h3>\n",
    "\n",
    "<ol style=\"color:#222\">\n",
    "    <li>Lê o primeiro arquivo da lista e o passa para um DataFrame (df1)</li>\n",
    "    <li>Lê o segundo arquivo da lista e o passa para outro DataFrame (df2)</li>\n",
    "    <li>Concatena os dois DataFrames em um terceiro (df_acum)</li>\n",
    "    <li>Itera sobre os demais arquivos, lendo cada um deles, aplicando strip(), a função de filtro do 23º BPM e depois o adiciona ao DataFrame df_acum</li>\n",
    "    <li>Retira as duplicatas, pelo campo 'RAT.NUM_ATIVIDADE'</li>\n",
    "    <li>Adiciona colunas data/hora início e término, tempo em datetime e tempo em inteiro </li>\n",
    "    <li>Aplica .upper() nas colunas usadas para classificação.</li>\n",
    "    <li>Classifica por Setores</li>\n",
    "    <li>Classifica por Cias</li>\n",
    "    <li>Insere os dados de df_acum no banco de dados gdo.db: (tabela tbl_rat)</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wendel/.asdf/installs/python/anaconda3-2019.07/lib/python3.7/site-packages/pandas/core/generic.py:2531: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  dtype=dtype, method=method)\n"
     ]
    }
   ],
   "source": [
    "# df_classif = pd.read_csv('files/classificadores.csv')\n",
    "# df_classif = df_classif.apply(lambda col:col.str.upper())\n",
    "# df_classif.set_index( df_classif['MUNICIPIO'] + \" \" + df_classif['VALIDADOR_TIPO'] + \" \" + df_classif['VALIDADOR'], inplace=True)\n",
    "# df_classif['SETOR'] = df_classif['SETOR'].str.replace('LOURDES ITATIAIUCU', 'LOURDES/ITATIAIUCU')\n",
    "# df_classif['SETOR'] = df_classif['SETOR'].str.replace('CENTRO PADRE EUSTAQUIO', 'CENTRO/PADRE EUSTAQUIO')\n",
    "# df_classif['SETOR'] = df_classif['SETOR'].str.replace('SANTANENSE MORADA NOVA', 'SANTANENSE/MORADA NOVA')\n",
    "# df_classif = df_classif.reset_index().drop_duplicates('index').set_index('index')\n",
    "\n",
    "\n",
    "# def filter_23(df):\n",
    "#     return df[\n",
    "#         df['MUNICIPIO'].isin([\n",
    "#             'DIVINOPOLIS',\n",
    "#             'ITAUNA',\n",
    "#             'ITATIAIUCU',\n",
    "#             'CARMO DO CAJURU',\n",
    "#             'SAO GONCALO DO PARA',\n",
    "#             'CLAUDIO'\n",
    "#         ])\n",
    "#     ]\n",
    "\n",
    "\n",
    "# df1 = pd.read_csv('files/RAT/' + rats_files[0], error_bad_lines=False, sep='|')\n",
    "# df1 = df1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# df1 = filter_23(df1)\n",
    "\n",
    "# df2 = pd.read_csv('files/RAT/' + rats_files[1], error_bad_lines=False, sep='|')\n",
    "# df2 = df2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# df2 = filter_23(df2)\n",
    "\n",
    "# df_acum = pd.concat([df1, df2])\n",
    "\n",
    "# for rat_file in rats_files[2:]:\n",
    "#     df_aux = pd.read_csv('files/RAT/' + rat_file, error_bad_lines=False, sep='|')\n",
    "#     df_aux = df_aux.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "#     df_aux = filter_23(df_aux)\n",
    "#     df_acum = pd.concat([df_acum, df_aux])\n",
    "\n",
    "# df_acum.drop_duplicates(subset='RAT.NUM_ATIVIDADE', keep='last', inplace=True)\n",
    "\n",
    "# s_dta_in = df_acum['DTA_INICIO'] + \" \" + df_acum['HRA_INICIO']\n",
    "# df_acum.loc[:,'DTA_HRA_INICIO_DT'] = pd.to_datetime( s_dta_in, format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "# del s_dta_in\n",
    "\n",
    "# s_dta_ter = df_acum.loc[:,'DTA_TERMINO'] + \" \" + df_acum.loc[:,'HRA_TERMINO']\n",
    "# df_acum.loc[:,'DTA_HRA_TERMINO_DT'] = pd.to_datetime( s_dta_ter, format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "# del s_dta_ter\n",
    "\n",
    "# df_acum.loc[:,'TEMPO_DT'] = df_acum['DTA_HRA_TERMINO_DT'] - df_acum['DTA_HRA_INICIO_DT']\n",
    "\n",
    "# df_acum.loc[:,'TEMPO_INT'] = df_acum['TEMPO_DT'].dt.total_seconds() / 60\n",
    "\n",
    "# df_acum.loc[:,'MES'] = df_acum.loc[:,'DTA_HRA_INICIO_DT'].dt.month\n",
    "\n",
    "# df_acum.loc[:,'ANO'] = df_acum.loc[:,'DTA_HRA_INICIO_DT'].dt.year\n",
    "\n",
    "\n",
    "# for field in ['TEMPO_INT','ANO','MES']:\n",
    "#     df_acum[field].fillna(0, inplace=True)\n",
    "#     df_acum[field] = df_acum[field].astype('int32')\n",
    "\n",
    "# cols_classif = [\n",
    "#     'MUNICIPIO',\n",
    "#     'LOGRADOURO',\n",
    "#     'DES_ENDERECO',\n",
    "#     'COMPLEMENTO_ENDERECO',\n",
    "#     'NOME_BAIRRO',\n",
    "#     'LOGRADOURO2',\n",
    "#     'DES_ENDERECO2'\n",
    "# ]\n",
    "# df_acum[cols_classif] = df_acum[cols_classif].apply(lambda col: col.str.upper())\n",
    "\n",
    "\n",
    "# def classifica_setor(row):\n",
    "#     mun = row['MUNICIPIO']\n",
    "#     if mun == 'CLAUDIO':        \n",
    "#         return 'CLAUDIO'\n",
    "#     elif mun == 'ITATIAIUCU':\n",
    "#         return 'LOURDES/ITATIAIUCU'\n",
    "#     elif mun in ('CARMO DO CAJURU', 'SAO GONCALO DO PARA'):             \n",
    "#         return 'CARMO DO CAJURU/SAO GONCALO DO PARA'    \n",
    "#     elif ( mun + \" N_RAT \" + row['RAT.NUM_ATIVIDADE'] ) in df_classif.index:\n",
    "#         return df_classif.loc[mun+\" N_RAT \"+row['RAT.NUM_ATIVIDADE'], 'SETOR']\n",
    "#     elif mun + ' BAIRRO ' + row['NOME_BAIRRO'] in df_classif.index:       \n",
    "#         return ( df_classif.loc[mun + ' BAIRRO ' + row['NOME_BAIRRO'].upper(), 'SETOR'] ).upper()\n",
    "#     elif mun + ' LOGRADOURO ' + row['LOGRADOURO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO ' + row['LOGRADOURO'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO ' + row['DES_ENDERECO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO ' + row['DES_ENDERECO'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO2'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO2'].upper(), 'SETOR']\n",
    "#     elif mun + ' COMPLEMENTO_END ' + row['COMPLEMENTO_ENDERECO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' COMPLEMENTO_END ' + row['COMPLEMENTO_ENDERECO'].upper(), 'SETOR']\n",
    "#     elif ( mun + ' COMPLEMENTO_END ' + row['DES_ENDERECO'] ) in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' COMPLEMENTO_END ' + row['DES_ENDERECO'], 'SETOR']    \n",
    "#     else:\n",
    "#         return 'other'\n",
    "\n",
    "# df_acum['SETOR'] = df_acum.apply(lambda row: classifica_setor(row), axis=1)\n",
    "\n",
    "# conds=[\n",
    "#     df_acum['MUNICIPIO'].isin(['ITAUNA','ITATIAIUCU']),\n",
    "#     df_acum['SETOR'].isin(['HIPER CENTRO','BOM PASTOR','ALTO GOIAS']),\n",
    "#     df_acum['SETOR'].isin(['PLANALTO','SAO JOSE','CLAUDIO']),\n",
    "#     df_acum['SETOR'].isin(['NITEROI','PORTO VELHO','CARMO DO CAJURU/SAO GONCALO DO PARA']),\n",
    "    \n",
    "# ]\n",
    "# res=['51 CIA','53 CIA','139 CIA','142 CIA']\n",
    "# df_acum['CIA'] = np.select(conds,res,default='other')\n",
    "\n",
    "# df_acum.to_sql('tbl_rat', 'sqlite:///gdo.db', if_exists='replace', index=False)\n",
    "# del df_acum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#0A0;margin:10px \">Importação, para o Banco de Dados, de todos os arquivos tipo RAT_VEICULOS, RAT_VIATURA e RAT_PRODUTIVIDADE</h2>\n",
    "<h3 style=\"color:#00A; margin:10px\">Importa somente os dados do 23º BPM</h3>\n",
    "\n",
    "<ol style=\"color:#222\">\n",
    "    <li>Importa do Banco de Dados, a tabela rat, para o df_rat, atribuindo RAT.NUM_ATIVIDADE para o index</li>\n",
    "    <li>Lê o primeiro arquivo da lista e o passa para um DataFrame (dfv1, dfe1, dfp1)</li>\n",
    "    <li>Lê o segundo arquivo da lista e o passa para outro DataFrame (dfv2, dfe2, dfp2)</li>\n",
    "    <li>Concatena os dois DataFrames em um terceiro (df_acum)</li>\n",
    "    <li>Itera sobre os demais arquivos, lendo cada um deles, aplicando strip(), a função de filtro do 23º BPM e depois o adiciona ao DataFrame df_acum</li>    \n",
    "    <li>Insere os dados no banco de dados</li>        \n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RAT.NUM_ATIVIDADE</th>\n",
       "      <th>NAT.CODIGO</th>\n",
       "      <th>NAT.DESCRICAO</th>\n",
       "      <th>DTA_HRA_INCLUSAO</th>\n",
       "      <th>DTA_INICIO</th>\n",
       "      <th>HRA_INICIO</th>\n",
       "      <th>DTA_TERMINO</th>\n",
       "      <th>HRA_TERMINO</th>\n",
       "      <th>DES_ALVO_EVENTO</th>\n",
       "      <th>DES_LUGAR</th>\n",
       "      <th>...</th>\n",
       "      <th>NOM_UNIDADE_AREA</th>\n",
       "      <th>DIGITADOR</th>\n",
       "      <th>DTA_HRA_INICIO_DT</th>\n",
       "      <th>DTA_HRA_TERMINO_DT</th>\n",
       "      <th>TEMPO_DT</th>\n",
       "      <th>TEMPO_INT</th>\n",
       "      <th>MES</th>\n",
       "      <th>ANO</th>\n",
       "      <th>SETOR</th>\n",
       "      <th>CIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-046472984-001</td>\n",
       "      <td>Y07001</td>\n",
       "      <td>OPERACAO DE BATIDA POLICIAL</td>\n",
       "      <td>17/10/2018</td>\n",
       "      <td>17/10/2018</td>\n",
       "      <td>18:43</td>\n",
       "      <td>17/10/2018</td>\n",
       "      <td>19:00</td>\n",
       "      <td>TRANSEUNTE</td>\n",
       "      <td>VIA DE ACESSO PUBLICA</td>\n",
       "      <td>...</td>\n",
       "      <td>53 CIA PM/23 BPM/7 RPM</td>\n",
       "      <td>PM1569110</td>\n",
       "      <td>2018-10-17 18:43:00</td>\n",
       "      <td>2018-10-17 19:00:00</td>\n",
       "      <td>1.020000e+12</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>PLANALTO</td>\n",
       "      <td>139 CIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-046878708-001</td>\n",
       "      <td>Y12001</td>\n",
       "      <td>FISCALIZACAO DE LOCAIS DE DESMATE</td>\n",
       "      <td>20/10/2018</td>\n",
       "      <td>20/10/2018</td>\n",
       "      <td>12:39</td>\n",
       "      <td>20/10/2018</td>\n",
       "      <td>15:00</td>\n",
       "      <td>FAZENDA</td>\n",
       "      <td>FAZENDA</td>\n",
       "      <td>...</td>\n",
       "      <td>3 PEL/139 CIA PM/23 BPM/7 RPM</td>\n",
       "      <td>PM1502681</td>\n",
       "      <td>2018-10-20 12:39:00</td>\n",
       "      <td>2018-10-20 15:00:00</td>\n",
       "      <td>8.460000e+12</td>\n",
       "      <td>141</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>CLAUDIO</td>\n",
       "      <td>139 CIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-047006854-001</td>\n",
       "      <td>Y11006</td>\n",
       "      <td>FISCALIZACAO DE MAUS TRATOS A ANIMAIS</td>\n",
       "      <td>21/10/2018</td>\n",
       "      <td>21/10/2018</td>\n",
       "      <td>13:28</td>\n",
       "      <td>21/10/2018</td>\n",
       "      <td>16:00</td>\n",
       "      <td>FAZENDA</td>\n",
       "      <td>FAZENDA</td>\n",
       "      <td>...</td>\n",
       "      <td>142 CIA PM/23 BPM/7 RPM</td>\n",
       "      <td>PM1502681</td>\n",
       "      <td>2018-10-21 13:28:00</td>\n",
       "      <td>2018-10-21 16:00:00</td>\n",
       "      <td>9.120000e+12</td>\n",
       "      <td>152</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>PORTO VELHO</td>\n",
       "      <td>142 CIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-048663517-001</td>\n",
       "      <td>Y12001</td>\n",
       "      <td>FISCALIZACAO DE LOCAIS DE DESMATE</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>07:23</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>10:00</td>\n",
       "      <td>FAZENDA</td>\n",
       "      <td>FAZENDA</td>\n",
       "      <td>...</td>\n",
       "      <td>53 CIA PM/23 BPM/7 RPM</td>\n",
       "      <td>PM1502681</td>\n",
       "      <td>2018-10-31 07:23:00</td>\n",
       "      <td>2018-10-31 10:00:00</td>\n",
       "      <td>9.420000e+12</td>\n",
       "      <td>157</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>PLANALTO</td>\n",
       "      <td>139 CIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-049254756-001</td>\n",
       "      <td>Y08999</td>\n",
       "      <td>OUTRAS ESCOLTAS</td>\n",
       "      <td>04/11/2018</td>\n",
       "      <td>04/11/2018</td>\n",
       "      <td>08:22</td>\n",
       "      <td>04/11/2018</td>\n",
       "      <td>10:00</td>\n",
       "      <td>CARGAS</td>\n",
       "      <td>VIA DE ACESSO PUBLICA</td>\n",
       "      <td>...</td>\n",
       "      <td>53 CIA PM/23 BPM/7 RPM</td>\n",
       "      <td>PM1326123</td>\n",
       "      <td>2018-11-04 08:22:00</td>\n",
       "      <td>2018-11-04 10:00:00</td>\n",
       "      <td>5.880000e+12</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>BOM PASTOR</td>\n",
       "      <td>53 CIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RAT.NUM_ATIVIDADE NAT.CODIGO                          NAT.DESCRICAO  \\\n",
       "0  2018-046472984-001     Y07001            OPERACAO DE BATIDA POLICIAL   \n",
       "1  2018-046878708-001     Y12001      FISCALIZACAO DE LOCAIS DE DESMATE   \n",
       "2  2018-047006854-001     Y11006  FISCALIZACAO DE MAUS TRATOS A ANIMAIS   \n",
       "3  2018-048663517-001     Y12001      FISCALIZACAO DE LOCAIS DE DESMATE   \n",
       "4  2018-049254756-001     Y08999                        OUTRAS ESCOLTAS   \n",
       "\n",
       "  DTA_HRA_INCLUSAO  DTA_INICIO HRA_INICIO DTA_TERMINO HRA_TERMINO  \\\n",
       "0       17/10/2018  17/10/2018      18:43  17/10/2018       19:00   \n",
       "1       20/10/2018  20/10/2018      12:39  20/10/2018       15:00   \n",
       "2       21/10/2018  21/10/2018      13:28  21/10/2018       16:00   \n",
       "3       31/10/2018  31/10/2018      07:23  31/10/2018       10:00   \n",
       "4       04/11/2018  04/11/2018      08:22  04/11/2018       10:00   \n",
       "\n",
       "  DES_ALVO_EVENTO              DES_LUGAR  ...               NOM_UNIDADE_AREA  \\\n",
       "0      TRANSEUNTE  VIA DE ACESSO PUBLICA  ...         53 CIA PM/23 BPM/7 RPM   \n",
       "1         FAZENDA                FAZENDA  ...  3 PEL/139 CIA PM/23 BPM/7 RPM   \n",
       "2         FAZENDA                FAZENDA  ...        142 CIA PM/23 BPM/7 RPM   \n",
       "3         FAZENDA                FAZENDA  ...         53 CIA PM/23 BPM/7 RPM   \n",
       "4          CARGAS  VIA DE ACESSO PUBLICA  ...         53 CIA PM/23 BPM/7 RPM   \n",
       "\n",
       "   DIGITADOR   DTA_HRA_INICIO_DT  DTA_HRA_TERMINO_DT      TEMPO_DT TEMPO_INT  \\\n",
       "0  PM1569110 2018-10-17 18:43:00 2018-10-17 19:00:00  1.020000e+12        17   \n",
       "1  PM1502681 2018-10-20 12:39:00 2018-10-20 15:00:00  8.460000e+12       141   \n",
       "2  PM1502681 2018-10-21 13:28:00 2018-10-21 16:00:00  9.120000e+12       152   \n",
       "3  PM1502681 2018-10-31 07:23:00 2018-10-31 10:00:00  9.420000e+12       157   \n",
       "4  PM1326123 2018-11-04 08:22:00 2018-11-04 10:00:00  5.880000e+12        98   \n",
       "\n",
       "  MES   ANO        SETOR      CIA  \n",
       "0  10  2018     PLANALTO  139 CIA  \n",
       "1  10  2018      CLAUDIO  139 CIA  \n",
       "2  10  2018  PORTO VELHO  142 CIA  \n",
       "3  10  2018     PLANALTO  139 CIA  \n",
       "4  11  2018   BOM PASTOR   53 CIA  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_ratv = pd.read_sql_table('tbl_rat', 'sqlite:///gdo.db')\n",
    "df_ratv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rat = pd.read_sql_table('tbl_rat', 'sqlite:///gdo.db')\n",
    "# df_rat.set_index('RAT.NUM_ATIVIDADE', inplace=True)\n",
    "\n",
    "# dfv1 = pd.read_csv('files/RAT/' + rats_viatura_files[0], error_bad_lines=False, sep='|')\n",
    "# dfv1 = dfv1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfv1 = dfv1[dfv1['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfv2 = pd.read_csv('files/RAT/' + rats_viatura_files[1], error_bad_lines=False, sep='|')\n",
    "# dfv2 = dfv2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfv2 = dfv2[dfv2['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfv_acum = pd.concat([dfv1, dfv2])\n",
    "\n",
    "\n",
    "# for rat_viatura_file in rats_viatura_files[2:]:\n",
    "#     dfv_aux = pd.read_csv('files/RAT/'+rat_viatura_file, sep='|')\n",
    "#     dfv_aux = dfv_aux.applymap(lambda col: col.strip() if type(col) == str else col)\n",
    "#     dfv_aux = dfv_aux[dfv_aux['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "#     dfv_acum = pd.concat([dfv_acum, dfv_aux])\n",
    "    \n",
    "# dfv_acum.to_sql('tbl_rat_veiculo', 'sqlite:///gdo.db', if_exists='replace', index=False)\n",
    "# del dfv_acum\n",
    "# del df_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rat = pd.read_sql_table('tbl_rat', 'sqlite:///gdo.db')\n",
    "# df_rat.set_index('RAT.NUM_ATIVIDADE', inplace=True)\n",
    "\n",
    "# dfe1 = pd.read_csv('files/RAT/' + rats_efetivo_files[0], error_bad_lines=False, sep='|')\n",
    "# dfe1 = dfe1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfe1 = dfe1[dfe1['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfe2 = pd.read_csv('files/RAT/' + rats_efetivo_files[1], error_bad_lines=False, sep='|')\n",
    "# dfe2 = dfe2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfe2 = dfe2[dfe2['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfe_acum = pd.concat([dfe1, dfe2])\n",
    "\n",
    "\n",
    "# for rat_efetivo_file in rats_efetivo_files[2:]:\n",
    "#     dfe_aux = pd.read_csv('files/RAT/'+rat_efetivo_file, sep='|')\n",
    "#     dfe_aux = dfe_aux.applymap(lambda col: col.strip() if type(col) == str else col)\n",
    "#     dfe_aux = dfe_aux[dfe_aux['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "#     dfe_acum = pd.concat([dfe_acum, dfe_aux])\n",
    "    \n",
    "# dfe_acum.to_sql('tbl_rat_efetivo', 'sqlite:///gdo.db', if_exists='replace', index=False)\n",
    "# del dfe_acum\n",
    "# del df_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rat = pd.read_sql_table('tbl_rat', 'sqlite:///gdo.db')\n",
    "# df_rat.set_index('RAT.NUM_ATIVIDADE', inplace=True)\n",
    "\n",
    "# dfp1 = pd.read_csv('files/RAT/' + rats_produtividade_files[0], error_bad_lines=False, sep='|')\n",
    "# dfp1 = dfp1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfp1 = dfp1[dfp1['RAT.NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfp2 = pd.read_csv('files/RAT/' + rats_produtividade_files[1], error_bad_lines=False, sep='|')\n",
    "# dfp2 = dfp2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfp2 = dfp2[dfp2['RAT.NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfp_acum = pd.concat([dfp1, dfp2])\n",
    "\n",
    "\n",
    "# for rat_produtividade_file in rats_produtividade_files[2:]:\n",
    "#     dfp_aux = pd.read_csv('files/RAT/'+rat_produtividade_file, sep='|')\n",
    "#     dfp_aux = dfp_aux.applymap(lambda col: col.strip() if type(col) == str else col)\n",
    "#     dfp_aux = dfp_aux[dfp_aux['RAT.NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "#     dfp_acum = pd.concat([dfp_acum, dfp_aux])\n",
    "    \n",
    "# dfp_acum.to_sql('tbl_rat_produtividade', 'sqlite:///gdo.db', if_exists='replace', index=False)\n",
    "# del df_rat\n",
    "# del dfp_acum"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
