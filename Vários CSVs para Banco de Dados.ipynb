{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:#00A'>O código adiante obtém os arquivos csv, por tipo (rat, rat_evetivo, rat_viatura e rat_produtividade) e os ordena por data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = os.getcwd()\n",
    "# rats_files_names = os.listdir(dir+'/files/RAT')\n",
    "# rat_pattern = re.compile('REDS_RAT_2')\n",
    "# rat_viatura_pattern = re.compile('RAT_VIATURA')\n",
    "# rat_efetivo_pattern = re.compile('RAT_EFETIVO')\n",
    "# rat_produtividade_pattern = re.compile('RAT_Produtividade')\n",
    "\n",
    "# rats_files = list()\n",
    "# rats_viatura_files = list()\n",
    "# rats_efetivo_files = list()\n",
    "# rats_produtividade_files = list()\n",
    "\n",
    "# for file_name in rats_files_names:\n",
    "#     is_rat = rat_pattern.search(file_name) != None\n",
    "#     is_rat_viatura = rat_viatura_pattern.search(file_name) != None\n",
    "#     is_rat_efetivo = rat_efetivo_pattern.search(file_name) != None\n",
    "#     is_rat_produtividade = rat_produtividade_pattern.search(file_name) != None\n",
    "#     if is_rat:\n",
    "#         rats_files.append(file_name)\n",
    "#     elif is_rat_viatura:\n",
    "#         rats_viatura_files.append(file_name)\n",
    "#     elif is_rat_efetivo:\n",
    "#         rats_efetivo_files.append(file_name)\n",
    "#     elif is_rat_produtividade:\n",
    "#         rats_produtividade_files.append(file_name)\n",
    "        \n",
    "# rats_files.sort(key=lambda name: int(name[9:17]))\n",
    "# rats_viatura_files.sort(key=lambda name: int(name[18:26]))\n",
    "# rats_efetivo_files.sort(key=lambda name: int(name[18:26]))\n",
    "# rats_produtividade_files.sort(key=lambda name: int(name[23:31]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#0A0;margin:10px \">Importação, para o Banco de Dados, de todos os arquivos tipo RAT</h2>\n",
    "<h3 style=\"color:#00A; margin:10px\">Importa somente os dados do 23º BPM</h3>\n",
    "\n",
    "<ol style=\"color:#222\">\n",
    "    <li>Lê o primeiro arquivo da lista e o passa para um DataFrame (df1)</li>\n",
    "    <li>Lê o segundo arquivo da lista e o passa para outro DataFrame (df2)</li>\n",
    "    <li>Concatena os dois DataFrames em um terceiro (df_acum)</li>\n",
    "    <li>Itera sobre os demais arquivos, lendo cada um deles, aplicando strip(), a função de filtro do 23º BPM e depois o adiciona ao DataFrame df_acum</li>\n",
    "    <li>Retira as duplicatas, pelo campo 'RAT.NUM_ATIVIDADE'</li>\n",
    "    <li>Adiciona colunas data/hora início e término, tempo em datetime e tempo em inteiro </li>\n",
    "    <li>Aplica .upper() nas colunas usadas para classificação.</li>\n",
    "    <li>Classifica por Setores</li>\n",
    "    <li>Classifica por Cias</li>\n",
    "    <li>Insere os dados de df_acum no banco de dados gdo.db: (tabela tbl_rat)</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seo23bpm/.asdf/installs/python/anaconda3-2019.10/lib/python3.7/site-packages/pandas/core/generic.py:2712: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "# df_classif = pd.read_csv('files/classificadores.csv')\n",
    "# df_classif = df_classif.apply(lambda col:col.str.upper())\n",
    "# df_classif.set_index( df_classif['MUNICIPIO'] + \" \" + df_classif['VALIDADOR_TIPO'] + \" \" + df_classif['VALIDADOR'], inplace=True)\n",
    "# df_classif['SETOR'] = df_classif['SETOR'].str.replace('LOURDES ITATIAIUCU', 'LOURDES/ITATIAIUCU')\n",
    "# df_classif['SETOR'] = df_classif['SETOR'].str.replace('CENTRO PADRE EUSTAQUIO', 'CENTRO/PADRE EUSTAQUIO')\n",
    "# df_classif['SETOR'] = df_classif['SETOR'].str.replace('SANTANENSE MORADA NOVA', 'SANTANENSE/MORADA NOVA')\n",
    "# df_classif = df_classif.reset_index().drop_duplicates('index').set_index('index')\n",
    "\n",
    "\n",
    "# def filter_23(df):\n",
    "#     return df[\n",
    "#         df['MUNICIPIO'].isin([\n",
    "#             'DIVINOPOLIS',\n",
    "#             'ITAUNA',\n",
    "#             'ITATIAIUCU',\n",
    "#             'CARMO DO CAJURU',\n",
    "#             'SAO GONCALO DO PARA',\n",
    "#             'CLAUDIO'\n",
    "#         ])\n",
    "#     ]\n",
    "\n",
    "\n",
    "# df1 = pd.read_csv('files/RAT/' + rats_files[0], error_bad_lines=False, sep='|')\n",
    "# df1 = df1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# df1 = filter_23(df1)\n",
    "\n",
    "# df2 = pd.read_csv('files/RAT/' + rats_files[1], error_bad_lines=False, sep='|')\n",
    "# df2 = df2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# df2 = filter_23(df2)\n",
    "\n",
    "# df_acum = pd.concat([df1, df2])\n",
    "\n",
    "# for rat_file in rats_files[2:]:\n",
    "#     df_aux = pd.read_csv('files/RAT/' + rat_file, error_bad_lines=False, sep='|')\n",
    "#     df_aux = df_aux.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "#     df_aux = filter_23(df_aux)\n",
    "#     df_acum = pd.concat([df_acum, df_aux])\n",
    "\n",
    "# df_acum.drop_duplicates(subset='RAT.NUM_ATIVIDADE', keep='last', inplace=True)\n",
    "\n",
    "# df_acum.loc[:,'DTA_HRA_INICIO'] = df_acum['DTA_INICIO'] + \" \" + df_acum['HRA_INICIO']\n",
    "# df_acum.loc[:,'DTA_HRA_INICIO_DT'] = pd.to_datetime( df_acum['DTA_HRA_INICIO'], format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "\n",
    "# df_acum.loc[:,'DTA_HRA_TERMINO'] = df_acum.loc[:,'DTA_TERMINO'] + \" \" + df_acum.loc[:,'HRA_TERMINO']\n",
    "# df_acum.loc[:,'DTA_HRA_TERMINO_DT'] = pd.to_datetime( df_acum.loc[:,'DTA_HRA_TERMINO'], format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "\n",
    "# df_acum.loc[:,'MES'] = df_acum.loc[:,'DTA_HRA_INICIO_DT'].dt.month\n",
    "# df_acum.loc[:,'ANO'] = df_acum.loc[:,'DTA_HRA_INICIO_DT'].dt.year\n",
    "\n",
    "# df_acum.loc[:,'TEMPO_DT'] = df_acum['DTA_HRA_TERMINO_DT'] - df_acum['DTA_HRA_INICIO_DT']\n",
    "\n",
    "# df_acum.loc[:,'TEMPO_INT'] = df_acum['TEMPO_DT'].dt.total_seconds() / 60\n",
    "\n",
    "# cols_classif = [\n",
    "#     'MUNICIPIO',\n",
    "#     'LOGRADOURO',\n",
    "#     'DES_ENDERECO',\n",
    "#     'COMPLEMENTO_ENDERECO',\n",
    "#     'NOME_BAIRRO',\n",
    "#     'LOGRADOURO2',\n",
    "#     'DES_ENDERECO2'\n",
    "# ]\n",
    "# df_acum[cols_classif] = df_acum[cols_classif].apply(lambda col: col.str.upper())\n",
    "\n",
    "\n",
    "# def classifica_setor(row):\n",
    "#     mun = row['MUNICIPIO']\n",
    "#     if mun == 'CLAUDIO':        \n",
    "#         return 'CLAUDIO'\n",
    "#     elif mun == 'ITATIAIUCU':\n",
    "#         return 'LOURDES/ITATIAIUCU'\n",
    "#     elif mun in ('CARMO DO CAJURU', 'SAO GONCALO DO PARA'):             \n",
    "#         return 'CARMO DO CAJURU/SAO GONCALO DO PARA'    \n",
    "#     elif ( mun + \" N_RAT \" + row['RAT.NUM_ATIVIDADE'] ) in df_classif.index:\n",
    "#         return df_classif.loc[mun+\" N_RAT \"+row['RAT.NUM_ATIVIDADE'], 'SETOR']\n",
    "#     elif mun + ' BAIRRO ' + row['NOME_BAIRRO'] in df_classif.index:       \n",
    "#         return ( df_classif.loc[mun + ' BAIRRO ' + row['NOME_BAIRRO'].upper(), 'SETOR'] ).upper()\n",
    "#     elif mun + ' LOGRADOURO ' + row['LOGRADOURO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO ' + row['LOGRADOURO'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO ' + row['DES_ENDERECO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO ' + row['DES_ENDERECO'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['LOGRADOURO2'].upper(), 'SETOR']\n",
    "#     elif mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO2'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' LOGRADOURO_NAO_CAD ' + row['DES_ENDERECO2'].upper(), 'SETOR']\n",
    "#     elif mun + ' COMPLEMENTO_END ' + row['COMPLEMENTO_ENDERECO'] in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' COMPLEMENTO_END ' + row['COMPLEMENTO_ENDERECO'].upper(), 'SETOR']\n",
    "#     elif ( mun + ' COMPLEMENTO_END ' + row['DES_ENDERECO'] ) in df_classif.index:\n",
    "#         return df_classif.loc[mun + ' COMPLEMENTO_END ' + row['DES_ENDERECO'], 'SETOR']    \n",
    "#     else:\n",
    "#         return 'other'\n",
    "\n",
    "# df_acum['SETOR'] = df_acum.apply(lambda row: classifica_setor(row), axis=1)\n",
    "\n",
    "# conds=[\n",
    "#     df_acum['MUNICIPIO'].isin(['ITAUNA','ITATIAIUCU']),\n",
    "#     df_acum['SETOR'].isin(['HIPER CENTRO','BOM PASTOR','ALTO GOIAS']),\n",
    "#     df_acum['SETOR'].isin(['PLANALTO','SAO JOSE','CLAUDIO']),\n",
    "#     df_acum['SETOR'].isin(['NITEROI','PORTO VELHO','CARMO DO CAJURU/SAO GONCALO DO PARA']),\n",
    "    \n",
    "# ]\n",
    "# res=['51 CIA','53 CIA','139 CIA','142 CIA']\n",
    "# df_acum['CIA'] = np.select(conds,res,default='other')\n",
    "\n",
    "# df_acum.to_sql('tbl_rat', 'sqlite:///gdo.db', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#0A0;margin:10px \">Importação, para o Banco de Dados, de todos os arquivos tipo RAT_VEICULOS, RAT_VIATURA e RAT_PRODUTIVIDADE</h2>\n",
    "<h3 style=\"color:#00A; margin:10px\">Importa somente os dados do 23º BPM</h3>\n",
    "\n",
    "<ol style=\"color:#222\">\n",
    "    <li>Importa do Banco de Dados, a tabela rat, para o df_rat, atribuindo RAT.NUM_ATIVIDADE para o index</li>\n",
    "    <li>Lê o primeiro arquivo da lista e o passa para um DataFrame (dfv1, dfe1, dfp1)</li>\n",
    "    <li>Lê o segundo arquivo da lista e o passa para outro DataFrame (dfv2, dfe2, dfp2)</li>\n",
    "    <li>Concatena os dois DataFrames em um terceiro (df_acum)</li>\n",
    "    <li>Itera sobre os demais arquivos, lendo cada um deles, aplicando strip(), a função de filtro do 23º BPM e depois o adiciona ao DataFrame df_acum</li>    \n",
    "    <li>Insere os dados no banco de dados</li>        \n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rat = pd.read_sql_table('tbl_rat', 'sqlite:///gdo.db')\n",
    "# df_rat.set_index('RAT.NUM_ATIVIDADE', inplace=True)\n",
    "\n",
    "# dfv1 = pd.read_csv('files/RAT/' + rats_viatura_files[0], error_bad_lines=False, sep='|')\n",
    "# dfv1 = dfv1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfv1 = dfv1[dfv1['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfv2 = pd.read_csv('files/RAT/' + rats_viatura_files[1], error_bad_lines=False, sep='|')\n",
    "# dfv2 = dfv2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfv2 = dfv2[dfv2['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfv_acum = pd.concat([dfv1, dfv2])\n",
    "\n",
    "\n",
    "# for rat_viatura_file in rats_viatura_files[2:]:\n",
    "#     dfv_aux = pd.read_csv('files/RAT/'+rat_viatura_file, sep='|')\n",
    "#     dfv_aux = dfv_aux.applymap(lambda col: col.strip() if type(col) == str else col)\n",
    "#     dfv_aux = dfv_aux[dfv_aux['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "#     dfv_acum = pd.concat([dfv_acum, dfv_aux])\n",
    "    \n",
    "# dfv_acum.to_sql('tbl_rat_veiculo', 'sqlite:///gdo.db', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rat = pd.read_sql_table('tbl_rat', 'sqlite:///gdo.db')\n",
    "# df_rat.set_index('RAT.NUM_ATIVIDADE', inplace=True)\n",
    "\n",
    "# dfe1 = pd.read_csv('files/RAT/' + rats_efetivo_files[0], error_bad_lines=False, sep='|')\n",
    "# dfe1 = dfe1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfe1 = dfe1[dfe1['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfe2 = pd.read_csv('files/RAT/' + rats_efetivo_files[1], error_bad_lines=False, sep='|')\n",
    "# dfe2 = dfe2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfe2 = dfe2[dfe2['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfe_acum = pd.concat([dfe1, dfe2])\n",
    "\n",
    "\n",
    "# for rat_efetivo_file in rats_efetivo_files[2:]:\n",
    "#     dfe_aux = pd.read_csv('files/RAT/'+rat_efetivo_file, sep='|')\n",
    "#     dfe_aux = dfe_aux.applymap(lambda col: col.strip() if type(col) == str else col)\n",
    "#     dfe_aux = dfe_aux[dfe_aux['NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "#     dfe_acum = pd.concat([dfe_acum, dfe_aux])\n",
    "    \n",
    "# dfe_acum.to_sql('tbl_rat_efetivo', 'sqlite:///gdo.db', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rat = pd.read_sql_table('tbl_rat', 'sqlite:///gdo.db')\n",
    "# df_rat.set_index('RAT.NUM_ATIVIDADE', inplace=True)\n",
    "\n",
    "# dfp1 = pd.read_csv('files/RAT/' + rats_produtividade_files[0], error_bad_lines=False, sep='|')\n",
    "# dfp1 = dfp1.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfp1 = dfp1[dfp1['RAT.NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfp2 = pd.read_csv('files/RAT/' + rats_produtividade_files[1], error_bad_lines=False, sep='|')\n",
    "# dfp2 = dfp2.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "# dfp2 = dfp2[dfp2['RAT.NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "\n",
    "# dfp_acum = pd.concat([dfp1, dfp2])\n",
    "\n",
    "\n",
    "# for rat_produtividade_file in rats_produtividade_files[2:]:\n",
    "#     dfp_aux = pd.read_csv('files/RAT/'+rat_produtividade_file, sep='|')\n",
    "#     dfp_aux = dfp_aux.applymap(lambda col: col.strip() if type(col) == str else col)\n",
    "#     dfp_aux = dfp_aux[dfp_aux['RAT.NUM_ATIVIDADE'].isin(df_rat.index)]\n",
    "#     dfp_acum = pd.concat([dfp_acum, dfp_aux])\n",
    "    \n",
    "# dfp_acum.to_sql('tbl_rat_produtividade', 'sqlite:///gdo.db', if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
